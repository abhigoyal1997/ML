{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('fashion-mnist')\n",
    "\n",
    "from utils.mnist_reader import load_mnist\n",
    "\n",
    "X_train, y_train = load_mnist('fashion-mnist/data/fashion', kind='train')\n",
    "X_test, y_test = load_mnist('fashion-mnist/data/fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from numba import njit\n",
    "from random import shuffle\n",
    "from typing import Dict, List, Tuple, Iterable\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 28, 28, 1) (54000,)\n",
      "(6000, 28, 28, 1) (6000,)\n",
      "(10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((-1, 28, 28, 1))\n",
    "X_test = X_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "val_size = int(len(X_train)*0.1)\n",
    "\n",
    "idx = np.arange(len(X_train))\n",
    "shuffle(idx)\n",
    "X_train, y_train = X_train[idx], y_train[idx]\n",
    "X_val, y_val = X_train[:val_size], y_train[:val_size]\n",
    "X_train, y_train = X_train[val_size:], y_train[val_size:]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(X_train[np.random.randint(len(X_train))].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(data: Tuple, batch_size: int, train: bool=False):\n",
    "    if train:\n",
    "        idx = np.arange(len(X_train))\n",
    "        shuffle(idx)\n",
    "        data = [x[idx] for x in data]\n",
    "        \n",
    "    for i in range(0, len(data[0]), batch_size):\n",
    "        yield tuple(x[i:i+batch_size] for x in data)\n",
    "        \n",
    "def prepare_inputs(X: np.ndarray):\n",
    "    return (X / 255) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    def __init__(self, data: np.ndarray):\n",
    "        self.data = data\n",
    "        self.grad = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Parameter(data={self.data}, grad={self.grad})\"\n",
    "\n",
    "class Module:\n",
    "    def __init__(self, lazy: bool=False, **parameters: Dict[str, Parameter]):\n",
    "        self._parameters: Dict[str, Parameter] = parameters\n",
    "        self.training = False\n",
    "        self._is_init = not lazy\n",
    "        \n",
    "    def _init(self, *input_shapes: List[Tuple[int]]):\n",
    "        modules = {}\n",
    "        for k in dir(self):\n",
    "            if k == \"parameters\":\n",
    "                continue\n",
    "\n",
    "            v = getattr(self, k)\n",
    "            if isinstance(v, Module):\n",
    "                modules[k] = v\n",
    "            elif isinstance(v, Parameter):\n",
    "                self._parameters[k] = v\n",
    "        \n",
    "        for name, module in modules.items():\n",
    "            self._parameters.update({f\"{name}.{k}\": v for k,v in module.parameters.items()})\n",
    "        \n",
    "        self._is_init = True\n",
    "        \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        assert self._is_init, f\"{self.__class__.__name__} not initialized!\"\n",
    "        return self._parameters\n",
    "    \n",
    "    def __call__(self, *inputs):\n",
    "        if not self._is_init:\n",
    "            self._init(*[t.shape for t in inputs])\n",
    "\n",
    "        self._inputs = inputs\n",
    "        self._outputs = self.forward(*inputs)\n",
    "        return self._outputs\n",
    "    \n",
    "    def train(self, training: bool=True):\n",
    "        self.training = training\n",
    "        for k in dir(self):\n",
    "            if isinstance(getattr(self, k), Module):\n",
    "                getattr(self, k).train(training)\n",
    "        \n",
    "    def eval(self):\n",
    "        self.train(False)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        modules = []\n",
    "        for k in dir(self):\n",
    "            if k == \"parameters\":\n",
    "                continue\n",
    "\n",
    "            if isinstance(getattr(self, k), Module):\n",
    "                modules.append(f\"{getattr(self, k)}\")\n",
    "                \n",
    "        return f\"{self.__class__.__name__}(\\n\" + \"\\n\".join([\"\\t\"+module for module in \",\\n\".join(modules).split(\"\\n\")]) + \"\\n)\"\n",
    "    \n",
    "        \n",
    "class ModuleList(Module):\n",
    "    def __init__(self, modules: List[Module]=[]):\n",
    "        super().__init__()\n",
    "        self.modules = modules\n",
    "        \n",
    "    def _init(self, *_):\n",
    "        for i, module in enumerate(self.modules):\n",
    "            self._parameters.update({f\"{i}.{k}\": v for k,v in module.parameters.items()})\n",
    "        super()._init()\n",
    "\n",
    "    def train(self, training: bool=True):\n",
    "        for module in self.modules:\n",
    "            module.train()\n",
    "        super().train(training)\n",
    "            \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.modules)\n",
    "            \n",
    "    def __getitem__(self, idx: int) -> Module:\n",
    "        return self.modules[idx]\n",
    "            \n",
    "    def __iter__(self) -> Iterable[Module]:\n",
    "        for module in self.modules:\n",
    "            yield module\n",
    "            \n",
    "    def __repr__(self):\n",
    "        modules = \",\\n\".join([repr(module) for module in self.modules])\n",
    "        return \"ModuleList([\\n\" + \"\\n\".join([\"\\t\"+module for module in modules.split(\"\\n\")]) + \"\\n])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, output_features: int, input_features: int=None):\n",
    "        self.output_features = output_features\n",
    "        self.input_features = input_features\n",
    "        if self.input_features is not None:\n",
    "            super().__init__(lazy=False)\n",
    "            self._init((input_features,))\n",
    "        else:\n",
    "            super().__init__(lazy=True)\n",
    "        \n",
    "    def _init(self, *input_shapes: Tuple[int]):\n",
    "        self.input_features = input_shapes[0][-1]\n",
    "        self.w = Parameter(np.random.randn(self.input_features, self.output_features) * np.sqrt(2 / self.input_features))\n",
    "        self.b = Parameter(np.zeros(self.output_features))\n",
    "        super()._init(*input_shapes)\n",
    "        \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        return X @ self.w.data + self.b.data\n",
    "    \n",
    "    def backward(self, grad_output: np.ndarray):\n",
    "        assert (grad_output.shape == self._outputs.shape), f\"grad_output={grad_output.shape}, output={self._outputs.shape}, input={self._inputs[0].shape}\"\n",
    "        \n",
    "        X = self._inputs[0].reshape(-1, self._inputs[0].shape[-1])\n",
    "        grad_output_reshape = grad_output.reshape(-1, grad_output.shape[-1])\n",
    "        self.w.grad = (X.T) @ grad_output_reshape\n",
    "        self.b.grad = grad_output_reshape.sum(axis=0)\n",
    "        return grad_output @ self.w.data.T\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self._is_init:\n",
    "            return f\"Linear({self.w.data.shape[0]},{self.w.data.shape[1]})\"\n",
    "        return f\"Linear(UNKNOWN)\"\n",
    "    \n",
    "class ReLU(Module):\n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        self._mask = X > 0\n",
    "        return X * self._mask\n",
    "    \n",
    "    def backward(self, grad_output: np.ndarray):\n",
    "        return grad_output * self._mask\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"ReLU()\"\n",
    "    \n",
    "class Dropout(Module):\n",
    "    def __init__(self, dropout: float):\n",
    "        assert (0 <= dropout < 1)\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:        \n",
    "        if self.training:\n",
    "            self._mask = np.random.rand(*X.shape) > self.dropout\n",
    "            return (X * self._mask) / (1 - self.dropout)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
    "        return (grad_output * self._mask) / (1 - self.dropout)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Dropout({self.dropout})\"\n",
    "    \n",
    "class ResBlock(Module):\n",
    "    def __init__(self, hidden_size: int, dropout: float=0.0):\n",
    "        self.linear = Linear(hidden_size, hidden_size)\n",
    "        self.relu = ReLU()\n",
    "        self.dropout = Dropout(dropout)\n",
    "        super().__init__(**self.linear.parameters)\n",
    "        \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        return self.dropout(self.relu(self.linear(X)) + X)\n",
    "    \n",
    "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
    "        assert (grad_output.shape == self._outputs.shape), f\"grad_output={grad_output.shape}, output={self._outputs.shape}, input={self._inputs[0].shape}\"\n",
    "\n",
    "        return self.linear.backward(self.relu.backward(self.dropout.backward(grad_output))) + grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Im2Col(Module):\n",
    "    def __init__(self, kernel_size: Tuple[int], stride: Tuple[int]):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "\n",
    "    @njit\n",
    "    def _forward(X: np.ndarray, cols: np.ndarray, stride: Tuple[int]) -> np.ndarray:\n",
    "        Ho, Wo, kh, kw = cols.shape[1:-1]\n",
    "        sh, sw = stride\n",
    "        \n",
    "        for i in range(0, Ho):\n",
    "            for j in range(0, Wo):\n",
    "                cols[:, i, j] = X[:, i*sh:i*sh+kh, j*sw:j*sw+kw]\n",
    "                \n",
    "    @njit\n",
    "    def _backward(grad_output: np.ndarray, output: np.ndarray, stride: Tuple[int]) -> np.ndarray:\n",
    "        Ho, Wo, kh, kw = grad_output.shape[1:-1]\n",
    "        sh, sw = stride\n",
    "\n",
    "        for i in range(0, Ho):\n",
    "            for j in range(0, Wo):\n",
    "                output[:, i*sh:i*sh+kh, j*sw:j*sw+kw] += grad_output[:, i, j]\n",
    "    \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        kh, kw = self.kernel_size\n",
    "        sh, sw = self.stride\n",
    "        B, H, W, C = X.shape\n",
    "        Ho = (H - kh) // sh + 1\n",
    "        Wo = (W - kw) // sw + 1\n",
    "        \n",
    "        cols = np.empty((B, Ho, Wo, kh, kw, C))\n",
    "        Im2Col._forward(X, cols, self.stride)\n",
    "        return cols.reshape((*cols.shape[:3], -1))\n",
    "    \n",
    "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
    "        assert (grad_output.shape == self._outputs.shape), f\"grad_output={grad_output.shape}, output={self._outputs.shape}, input={self._inputs[0].shape}\"\n",
    "\n",
    "        output = np.zeros_like(self._inputs[0])\n",
    "        kh, kw = self.kernel_size\n",
    "        sh, sw = self.stride\n",
    "        B, H, W, C = output.shape\n",
    "        Ho = (H - kh) // sh + 1\n",
    "        Wo = (W - kw) // sw + 1\n",
    "        \n",
    "        grad_output = grad_output.reshape(B, Ho, Wo, kh, kw, C)\n",
    "        Im2Col._backward(grad_output, output, self.stride)\n",
    "        return output\n",
    "        \n",
    "\n",
    "class Conv2D(Module):\n",
    "    def __init__(self, output_channels: int, kernel_size: Tuple[int], stride: Tuple[int], input_channels: int=None):\n",
    "        self.output_channels = output_channels\n",
    "        self.input_channels = input_channels\n",
    "        if self.input_channels is not None:\n",
    "            super().__init__(lazy=False)\n",
    "            self._init((input_channels,))\n",
    "        else:\n",
    "            super().__init__(lazy=True)\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        \n",
    "    def _init(self, *input_shapes: List[Tuple[int]]):\n",
    "        self.im2col = Im2Col(self.kernel_size, self.stride)\n",
    "        kh, kw = self.kernel_size\n",
    "        self.input_channels = input_shapes[0][-1]\n",
    "        self.linear = Linear(self.output_channels, kh * kw * self.input_channels)\n",
    "        return super()._init(*input_shapes)\n",
    "        \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        X = self.im2col(X)\n",
    "        return self.linear(X)\n",
    "    \n",
    "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
    "        assert (grad_output.shape == self._outputs.shape), f\"grad_output={grad_output.shape}, output={self._outputs.shape}, input={self._inputs[0].shape}\"\n",
    "        return self.im2col.backward(self.linear.backward(grad_output))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self._is_init:\n",
    "            return f\"Conv2D(\\n\\tkernel_size={self.kernel_size},\\n\\tstride={self.stride},\\n\\tinput_channels={self.input_channels},\\n\\toutput_channels={self.output_channels})\"\n",
    "        return f\"Conv2D(UNKNOWN)\"\n",
    "    \n",
    "\n",
    "class Flatten(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        self._input_shape = X.shape\n",
    "        return X.reshape((X.shape[0], -1))\n",
    "    \n",
    "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
    "        return grad_output.reshape(self._input_shape)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Flatten()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self, input_shape: int, num_classes: int):\n",
    "        super().__init__(lazy=True)\n",
    "        H, W, C = input_shape\n",
    "        \n",
    "        self.layers = ModuleList([\n",
    "            Conv2D(16, (3, 3), (1, 1)), ReLU(),\n",
    "            Conv2D(16, (5, 5), (2, 2)), ReLU(),\n",
    "            Conv2D(16, (7, 7), (3, 3)), ReLU(),\n",
    "            Flatten(),\n",
    "            Linear(num_classes),\n",
    "        ])\n",
    "        \n",
    "        X = np.random.rand(1, H, W, C)\n",
    "        _ = self.forward(X)\n",
    "        self._init()\n",
    "        \n",
    "    def _init(self, *_):\n",
    "        self.layers._init()\n",
    "        return super()._init()\n",
    "        \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, grad_output: np.ndarray) -> np.ndarray:\n",
    "        for layer in reversed(self.layers):\n",
    "            grad_output = layer.backward(grad_output)\n",
    "        \n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z: np.ndarray) -> np.ndarray:\n",
    "    ez = np.exp(z - z.max(axis=-1, keepdims=True))\n",
    "    return ez / ez.sum(axis=-1, keepdims=True)\n",
    "\n",
    "def accuracy(preds: np.ndarray, targets: np.ndarray) -> float:\n",
    "    return (preds == targets).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(Module):\n",
    "    def forward(self, logits: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        logits -= logits.max(axis=-1, keepdims=True)\n",
    "        return (np.log(np.sum(np.exp(logits), axis=-1)) - logits[np.arange(len(y)), y]).mean()\n",
    "    \n",
    "    def backward(self, _) -> np.ndarray:\n",
    "        logits, y = self._inputs\n",
    "        grads = softmax(logits)\n",
    "        grads[np.arange(len(y)), y] -= 1\n",
    "        return grads / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, params: Dict[str, Parameter], lr: float, weight_decay: float=0.0, max_grad_norm: float=1.0):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        \n",
    "    def step(self):\n",
    "        for name, param in self.params.items():\n",
    "            assert param.data.shape == param.grad.shape, f\"{name}: param={param.data.shape}, grad={param.grad.shape}\"\n",
    "            param.grad *= self.max_grad_norm / max(self.max_grad_norm, (param.grad ** 2).sum())\n",
    "            param.data -= self.lr * (param.grad + self.weight_decay * param.data)\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        for param in self.params.values():\n",
    "            param.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.05\n",
    "weight_decay = 0.0\n",
    "num_epochs = 10\n",
    "\n",
    "model = Model((28, 28, 1), 10)\n",
    "loss_fn = Loss()\n",
    "optim = SGD(model.parameters, lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(pbar):\n",
    "    pbar.total = len(X_train)\n",
    "    train_loss = 0\n",
    "    num_train_samples = 0\n",
    "    model.train()\n",
    "    for X, y in data_loader((X_train, y_train), batch_size, True):\n",
    "        loss = loss_fn(model(prepare_inputs(X)), y)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        model.backward(loss_fn.backward(None))\n",
    "        optim.step()\n",
    "\n",
    "        train_loss += (loss * len(X)).item()\n",
    "        num_train_samples += len(X)\n",
    "        pbar.update(len(X))\n",
    "        pbar.set_postfix({\"train_loss\": train_loss / num_train_samples})\n",
    "        \n",
    "    return train_loss / num_train_samples\n",
    "        \n",
    "\n",
    "def evaluate(pbar, data):\n",
    "    X_val, y_val = data\n",
    "    pbar.total = len(X_val)\n",
    "    val_loss = 0\n",
    "    num_val_samples = 0\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    for X, y in data_loader((X_val, y_val), batch_size, False):\n",
    "        outputs = model(prepare_inputs(X))\n",
    "        loss = loss_fn(outputs, y)\n",
    "        preds += outputs.argmax(axis=-1).tolist()\n",
    "\n",
    "        val_loss += (loss * len(X)).item()\n",
    "        num_val_samples += len(X)\n",
    "        pbar.update(len(X))\n",
    "        pbar.set_postfix({\"val_loss\": val_loss / num_val_samples, \"accuracy\": accuracy(np.asarray(preds), y_val[:num_val_samples])})\n",
    "        \n",
    "    return val_loss / num_val_samples, accuracy(np.asarray(preds), y_val[:num_val_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bdde5dab724c5caad926d46c959579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial: val_loss=2.348135272145917, 0.11666666666666667\n",
      "Epoch 0: train_loss=0.7582534255080419, val_loss=0.5931811768288147, val_accuracy=0.786\n",
      "Epoch 1: train_loss=0.5394443036552121, val_loss=0.5053486906925858, val_accuracy=0.8196666666666667\n",
      "Epoch 2: train_loss=0.48119859965116396, val_loss=0.45663642466106846, val_accuracy=0.8385\n",
      "Epoch 3: train_loss=0.4393717763842523, val_loss=0.4310332297955454, val_accuracy=0.8433333333333334\n",
      "Epoch 4: train_loss=0.41029708461829184, val_loss=0.4025190237832872, val_accuracy=0.8551666666666666\n",
      "Epoch 5: train_loss=0.3892266218682508, val_loss=0.38078063680534663, val_accuracy=0.8621666666666666\n",
      "Epoch 6: train_loss=0.3692636188607124, val_loss=0.3683948485433998, val_accuracy=0.867\n",
      "Epoch 7: train_loss=0.3535428773903829, val_loss=0.35110731142903207, val_accuracy=0.869\n",
      "Epoch 8: train_loss=0.34066508574561183, val_loss=0.34430290952983267, val_accuracy=0.8721666666666666\n",
      "Epoch 9: train_loss=0.3288217616820675, val_loss=0.3289731341025195, val_accuracy=0.8771666666666667\n",
      "Test accuracy: test_loss=0.3574828116910451, 0.8708\n"
     ]
    }
   ],
   "source": [
    "with tqdm() as pbar:\n",
    "    pbar.set_description(\"Val\")\n",
    "    val_loss, val_accuracy = evaluate(pbar, (X_val, y_val))\n",
    "    print(f\"Initial: {val_loss=}, {val_accuracy}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        pbar.reset()\n",
    "        pbar.set_description(\"Train\")\n",
    "        train_loss = train_epoch(pbar)\n",
    "\n",
    "        pbar.reset()\n",
    "        pbar.set_description(\"Val\")\n",
    "        val_loss, val_accuracy = evaluate(pbar, (X_val, y_val))\n",
    "        \n",
    "        print(f\"Epoch {epoch}: {train_loss=}, {val_loss=}, {val_accuracy=}\")\n",
    "\n",
    "    pbar.set_description(\"Test\")\n",
    "    test_loss, test_accuracy = evaluate(pbar, (X_test, y_test))\n",
    "    \n",
    "print(f\"Test accuracy: {test_loss=}, {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
